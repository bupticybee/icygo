{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import sgf\n",
    "import pandas as pd\n",
    "from go_utils import *\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from AlphaGo.go import GameState\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import random\n",
    "from AlphaGo.preprocessing.game_converter import GameConverter\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from tflearn.data_flow import DataFlow,DataFlowStatus,FeedDictFlow\n",
    "from tflearn.data_utils import Preloader,ImagePreloader\n",
    "import scipy\n",
    "from PIL import Image\n",
    "import copy\n",
    "from utils import Dataset,ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GPU_CORE = 0\n",
    "BATCH_SIZE = 128\n",
    "BEGINING_LR = 0.01\n",
    "TESTIMG_WIDTH = 500\n",
    "model_name = '10_28_resnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy.copy([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GoPreloader(object):\n",
    "    def __init__(self,batch_size=64,datafile='data/sgf_list.csv'):\n",
    "        self.batch_size=batch_size\n",
    "        content = pd.read_csv(datafile,header=None,index_col=None)\n",
    "        self.filelist = [i[0] for i in content.get_values()]\n",
    "        self.pos = 0\n",
    "        self.feature_list = [\n",
    "            \"board\",\n",
    "            \"ones\",\n",
    "            \"turns_since\",\n",
    "            \"liberties\",\n",
    "            #\"capture_size\",\n",
    "            #\"self_atari_size\",\n",
    "            #\"liberties_after\",\n",
    "            #\"ladder_capture\",\n",
    "            #\"ladder_escape\",\n",
    "            \"sensibleness\",\n",
    "            \"zeros\"]\n",
    "        self.gc = GameConverter(self.feature_list)\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_iter = self.__iter(BATCH_SIZE)\n",
    "        \n",
    "    def cod2array(self,cod,size=19):\n",
    "        arr = np.zeros((size,size))\n",
    "        arr[cod[0]][cod[1]] = 1\n",
    "        return arr\n",
    "\n",
    "    def __iter(self,batch_size):\n",
    "        retgo,retpred = [],[]\n",
    "        while True:\n",
    "            filelist = copy.copy(self.filelist)\n",
    "            \n",
    "            random.shuffle(filelist)\n",
    "            for one_file in filelist:\n",
    "                game_iter = self.gc.convert_game(one_file,bd_size=19)\n",
    "                for x,y in game_iter:\n",
    "                    x = np.transpose(x,[0,2,3,1])\n",
    "                    y = self.cod2array(y)\n",
    "                    retgo.append(x)\n",
    "                    retpred.append(y)\n",
    "                    if len(retgo) >= batch_size:\n",
    "                        yield (np.concatenate(retgo,axis=0),np.asarray(retpred))\n",
    "                        retgo = []\n",
    "                        retpred = []\n",
    "\n",
    "    def __getitem__(self, id):\n",
    "        \n",
    "        x,y = self.batch_iter.__next__()\n",
    "        return x,y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainset = GoPreloader(datafile='data/train_list.csv')\n",
    "with tf.device(\"/gpu:{}\".format(GPU_CORE)):\n",
    "    coord = tf.train.Coordinator()\n",
    "    trainflow = FeedDictFlow({\n",
    "            'data':trainset,\n",
    "        },coord,batch_size=BATCH_SIZE,shuffle=True,continuous=True,num_threads=1)\n",
    "trainflow.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testset = GoPreloader(datafile='data/test_list.csv')\n",
    "with tf.device(\"/gpu:{}\".format(GPU_CORE)):\n",
    "    coord = tf.train.Coordinator()\n",
    "    testflow = FeedDictFlow({\n",
    "            'data':testset,\n",
    "        },coord,batch_size=BATCH_SIZE,shuffle=True,continuous=True,num_threads=1)\n",
    "testflow.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_x,sample_y = trainflow.next()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_x,sample_y = testflow.next()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sample_x,sample_y = trainset[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128, 19, 19, 22), (128, 19, 19))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_x.shape,sample_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def res_block(inputx,name,training,block_num=2,filters=256,kernel_size=(3,3)):\n",
    "    net = inputx\n",
    "    for i in range(block_num):\n",
    "        net = tf.layers.conv2d(net,filters=filters,kernel_size=kernel_size,activation=None,name=\"{}_res_conv{}\".format(name,i),padding='same')\n",
    "        net = tf.layers.batch_normalization(net,training=training,name=\"{}_res_bn{}\".format(name,i))\n",
    "        if i == block_num - 1:\n",
    "            net = tf.concat((inputx,net),axis=-1)\n",
    "        net = tf.nn.elu(net,name=\"{}_res_elu{}\".format(name,i))\n",
    "    return net\n",
    "\n",
    "def conv_block(inputx,name,training,block_num=1,filters=2,kernel_size=(1,1),out_shape=(19,19)):\n",
    "    net = inputx\n",
    "    for i in range(block_num):\n",
    "        net = tf.layers.conv2d(net,filters=filters,kernel_size=kernel_size,activation=None,name=\"{}_convblock_conv{}\".format(name,i),padding='same')\n",
    "        net = tf.layers.batch_normalization(net,training=training,name=\"{}_convblock_bn{}\".format(name,i))\n",
    "        net = tf.nn.elu(net,name=\"{}_convblock_elu{}\".format(name,i))\n",
    "    # net [None,19,19,2]\n",
    "    netshape = net.get_shape().as_list()\n",
    "    print(netshape)\n",
    "    net = tf.reshape(net,shape=(-1,netshape[1] * netshape[2] * netshape[3]))\n",
    "    net = tf.layers.dense(net,19 * 19,name=\"{}_dense\".format(name))\n",
    "    net = tf.nn.elu(net,name=\"{}_elu\".format(name))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_test_image_op(name):\n",
    "    prediction_result = tf.placeholder(tf.float32, [None, TESTIMG_WIDTH,TESTIMG_WIDTH,3 ])\n",
    "    prediction_result_op = tf.summary.image(name,prediction_result)\n",
    "    return prediction_result,prediction_result_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "NUM_RES_LAYERS = 10\n",
    "\n",
    "with tf.device(\"/gpu:{}\".format(GPU_CORE)):\n",
    "    X = tf.placeholder(tf.float32,[None,19,19,22])\n",
    "    y = tf.placeholder(tf.float32,[None,19,19])\n",
    "    training = tf.placeholder(tf.bool,name='training_mode')\n",
    "    learning_rate = tf.placeholder(tf.float32)\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    \n",
    "    net = X\n",
    "    for i in range(NUM_RES_LAYERS):\n",
    "        net = res_block(net,name=\"layer_{}\".format(i + 1),training=training)\n",
    "    \n",
    "    net_unsoftmax = conv_block(net,name=\"conv\",training=training)\n",
    "    \n",
    "    target = tf.reshape(y,(-1,19 * 19))\n",
    "    with tf.variable_scope(\"Loss\"):\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=target,logits=net_unsoftmax))\n",
    "        loss_summary = tf.summary.scalar(\"softmax_loss\",loss)\n",
    "    net_softmax = tf.nn.softmax(net_unsoftmax)\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(target,1), tf.argmax(net_softmax,1))\n",
    "    \n",
    "    \n",
    "    with tf.variable_scope(\"Accuracy\"):\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        acc_summary = tf.summary.scalar(\"top_one\",accuracy)\n",
    "        \n",
    "    summary_op = tf.summary.merge([loss_summary,acc_summary])\n",
    "    \n",
    "    \n",
    "    train_data,train_op = gen_test_image_op(\"train_data\")\n",
    "    pred_data,pred_op = gen_test_image_op(\"pred\")\n",
    "    label_data,label_op = gen_test_image_op(\"label\")\n",
    "    pic_op = tf.summary.merge([train_op,pred_op,label_op])\n",
    "    \n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=0.9)\n",
    "    train_op = optimizer.minimize(loss,global_step=global_step)\n",
    "    \n",
    "    train_summary_writer = tf.summary.FileWriter(\"./log/{}_train\".format(model_name), sess.graph)\n",
    "    test_summary_writer = tf.summary.FileWriter(\"./log/{}_test\".format(model_name), sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "tf.train.global_step(sess, global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"models/{}\".format(model_name)):\n",
    "    os.mkdir(\"models/{}\".format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def gen_plot(arr):\n",
    "    \"\"\"Create a pyplot plot and save to buffer.\"\"\"\n",
    "    buf = draw_board(arr)\n",
    "    plot_image = Image.open(buf)\n",
    "    pred_image = scipy.misc.imresize(scipy.asarray(plot_image),size=(TESTIMG_WIDTH,TESTIMG_WIDTH))\n",
    "    pred_image = pred_image[:,:,:3]\n",
    "    return pred_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_BATCH = 10000\n",
    "N_BATCH_TEST = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.restore(sess,'models/10_27_resnet/model_14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_epoch = 15\n",
    "one_batch = 1\n",
    "train_epoch = one_epoch\n",
    "train_batch = one_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "restore = True\n",
    "N_EPOCH = 100\n",
    "DECAY_EPOCH = 30\n",
    "\n",
    "class ExpVal:\n",
    "    def __init__(self,exp_a=0.97):\n",
    "        self.val = None\n",
    "        self.exp_a = exp_a\n",
    "    def update(self,newval):\n",
    "        if self.val == None:\n",
    "            self.val = newval\n",
    "        else:\n",
    "            self.val = self.exp_a * self.val + (1 - self.exp_a) * newval\n",
    "    def getval(self):\n",
    "        return round(self.val,2)\n",
    "    \n",
    "expacc = ExpVal()\n",
    "exploss = ExpVal()\n",
    "\n",
    "\n",
    "begining_learning_rate = 1e-1\n",
    "\n",
    "pred_image = None\n",
    "if restore == False:\n",
    "    train_epoch = 1\n",
    "    train_batch = 0\n",
    "for one_epoch in range(train_epoch,N_EPOCH):\n",
    "    train_epoch = one_epoch\n",
    "    pb = ProgressBar(worksum=N_BATCH * BATCH_SIZE,info=\" epoch {} batch {}\".format(train_epoch,train_batch))\n",
    "    pb.startjob()\n",
    "    \n",
    "    for one_batch in range(N_BATCH):\n",
    "        if restore == True and one_batch < train_batch:\n",
    "            pb.auto_display = False\n",
    "            pb.complete(BATCH_SIZE)\n",
    "            pb.auto_display = True\n",
    "            continue\n",
    "        else:\n",
    "            restore = False\n",
    "        train_batch = one_batch\n",
    "        \n",
    "        batch_x,batch_y = trainflow.next()['data']\n",
    "        batch_x = np.transpose(batch_x,[0,2,1,3])\n",
    "        batch_y = np.transpose(batch_y,[0,2,1])\n",
    "        \n",
    "        \n",
    "        # learning rate decay strategy\n",
    "        batch_lr = begining_learning_rate * 10 ** -(one_epoch // DECAY_EPOCH)\n",
    "        \n",
    "        batch_result,_,step_loss,step_acc,step_summary,step_value,step_summary = sess.run(\n",
    "            [net_unsoftmax,train_op,loss,accuracy,summary_op,global_step,summary_op],feed_dict={\n",
    "                X:batch_x,y:batch_y,learning_rate:batch_lr,training:True\n",
    "            })\n",
    "        train_summary_writer.add_summary(step_summary,step_value)\n",
    "        step_acc *= 100\n",
    "        expacc.update(step_acc)\n",
    "        exploss.update(step_loss)\n",
    "\n",
    "        if  one_batch % 100 == 0:\n",
    "            plot_x,plot_target,plot_pred = [],[],[]\n",
    "            for i in range(4):\n",
    "                plot_x.append(gen_plot(batch_x[i,:,:,0] - batch_x[i,:,:,1]))\n",
    "                plot_target.append(gen_plot(batch_y[i]))\n",
    "                index = np.argmax(batch_result[i].reshape(-1))\n",
    "                pp = np.zeros(19 * 19)\n",
    "                pp[index] = 1\n",
    "                pp = pp.reshape(19,19)\n",
    "                plot_pred.append(gen_plot(pp))\n",
    "            plot_x,plot_target,plot_pred = np.asarray(plot_x),np.asarray(plot_target),np.asarray(plot_pred)\n",
    "            step_img = sess.run(pic_op,feed_dict={train_data:plot_x,pred_data:plot_pred,label_data:plot_target})\n",
    "            train_summary_writer.add_summary(step_img,step_value)\n",
    "        \n",
    "        pb.info = \"EPOCH {} STEP {} LR {} ACC {} LOSS {} \".format(\n",
    "            one_epoch,one_batch,batch_lr,expacc.getval(),exploss.getval())\n",
    "        \n",
    "        pb.complete(BATCH_SIZE)\n",
    "    print()\n",
    "    accs = []\n",
    "    losses = []\n",
    "    pb = ProgressBar(worksum=N_BATCH_TEST * BATCH_SIZE,info=\"validating epoch {} batch {}\".format(train_epoch,train_batch))\n",
    "    pb.startjob()\n",
    "    for one_batch in range(N_BATCH_TEST):\n",
    "        batch_x,batch_y = testflow.next()['data']\n",
    "        batch_x = np.transpose(batch_x,[0,2,1,3])\n",
    "        batch_y = np.transpose(batch_y,[0,2,1])\n",
    "        batch_result,step_loss,step_acc,step_summary,step_value,step_summary = sess.run(\n",
    "            [net_unsoftmax,loss,accuracy,summary_op,global_step,summary_op],feed_dict={\n",
    "                X:batch_x,y:batch_y,training:True\n",
    "            })\n",
    "        test_summary_writer.add_summary(step_summary,step_value)\n",
    "        accs.append(step_acc)\n",
    "        losses.append(step_loss)\n",
    "        if one_batch % 100 == 0:\n",
    "            plot_x,plot_target,plot_pred = [],[],[]\n",
    "            for i in range(4):\n",
    "                plot_x.append(gen_plot(batch_x[i,:,:,0] - batch_x[i,:,:,1]))\n",
    "                plot_target.append(gen_plot(batch_y[i]))\n",
    "                index = np.argmax(batch_result[i].reshape(-1))\n",
    "                pp = np.zeros(19 * 19)\n",
    "                pp[index] = 1\n",
    "                pp = pp.reshape(19,19)\n",
    "                plot_pred.append(gen_plot(pp))\n",
    "            plot_x,plot_target,plot_pred = np.asarray(plot_x),np.asarray(plot_target),np.asarray(plot_pred)\n",
    "            step_img = sess.run(pic_op,feed_dict={train_data:plot_x,pred_data:plot_pred,label_data:plot_target})\n",
    "            test_summary_writer.add_summary(step_img,step_value + one_batch)\n",
    "        \n",
    "        pb.complete(BATCH_SIZE)\n",
    "    print(\"TEST ACC {} LOSS {}\".format(np.average(accs),np.average(losses)))\n",
    "    print()\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess,\"models/{}/model_{}\".format(model_name,one_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
